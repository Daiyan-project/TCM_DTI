{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import deepchem as dc\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from ast import literal_eval\n",
    "\n",
    "#文件路径准备\n",
    "basePath = os.getcwd()\n",
    "resultPath = basePath+'/results/'\n",
    "training_path = basePath+'/training_data/'\n",
    "external_path = basePath+'/external_data/'\n",
    "\n",
    "training_list = ['TCM2000_100t','TCM2000_30t','TCM2000_50t','TCM2000_80t','TCM_100t','TCM_30t','TCM_50t','TCM_80t']\n",
    "algorithm = 'DMPNN'\n",
    "# 没保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU测试\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "\n",
    "# cmd nvidia-smi -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ext(dataset_X, dataset_y, model, epoch, test_X, test_y,traindataset,tar_id): \n",
    "\n",
    "    train_dataset = dc.data.NumpyDataset(X=dataset_X, y=dataset_y)\n",
    "    test_dataset = dc.data.NumpyDataset(X=test_X, y=test_y)\n",
    "\n",
    "    loss = model.fit(train_dataset, nb_epoch=epoch)\n",
    "\n",
    "    y_true = test_dataset.y\n",
    "    y_pred = model.predict(test_dataset)[:,1]\n",
    "\n",
    "    aucroc = roc_auc_score(y_true, y_pred) \n",
    "    \n",
    "    # torch.save(model, external_path+algorithm+'_'+traindataset+'_'+tar_id+\".pt\")\n",
    "\n",
    "    return aucroc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置epoch, batch_size参数\n",
    "epoch = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.DataFrame()\n",
    "\n",
    "for traindataset in training_list:\n",
    "\n",
    "    params_data = pd.read_csv(resultPath+'DMPNN_'+traindataset+'_rocmean.csv')\n",
    "    params_data.insert(0, 'dataset', traindataset)\n",
    "    \n",
    "    target_list = os.listdir(external_path+'ex_'+traindataset)\n",
    "    target_list = [item[:-4] for item in target_list]\n",
    "    # print(traindataset)\n",
    "    \n",
    "    for tar_id in tqdm(target_list):\n",
    "\n",
    "        params = literal_eval(params_data.at[target_list.index(tar_id), 'best_params'])\n",
    "        featurizer = dc.feat.DMPNNFeaturizer()\n",
    "\n",
    "        # 加载训练集\n",
    "        smiles = pd.read_csv(training_path +traindataset+'/'+tar_id+'.csv', header=0,index_col=False)['c_smiles'].tolist()\n",
    "        labels = pd.read_csv(training_path +traindataset+'/'+tar_id+'.csv', header=0,index_col=False)['active_label'].tolist()\n",
    "        labels = np.array(labels).reshape((len(labels), 1))\n",
    "        X = featurizer.featurize(smiles)\n",
    "        dataset = dc.data.NumpyDataset(X=X, y=labels)\n",
    "        dataset_X = dataset.X\n",
    "        dataset_y = dataset.y\n",
    "\n",
    "        # 加载外部验证集\n",
    "        smiles = pd.read_csv(external_path +'ex_'+traindataset+'/'+tar_id+'.csv', header=0,index_col=False)['c_smiles'].tolist()\n",
    "        labels = pd.read_csv(external_path +'ex_'+traindataset+'/'+tar_id+'.csv', header=0,index_col=False)['active_label'].tolist()\n",
    "        labels = np.array(labels).reshape((len(labels), 1))\n",
    "        X = featurizer.featurize(smiles)\n",
    "        dataset = dc.data.NumpyDataset(X=X, y=labels)\n",
    "        test_X = dataset.X\n",
    "        test_y = dataset.y\n",
    "        \n",
    "\n",
    "        model = dc.models.GCNModel(\n",
    "            batch_size=batch_size, \n",
    "            learning_rate=0.001,\n",
    "            n_tasks=1,\n",
    "            mode='classification',\n",
    "            graph_conv_layers=params['graph_conv_layers'],\n",
    "            attention_hidden_size=params['attention_hidden_size'],\n",
    "            dense_layer_size=params['dense_layer_size_value'],\n",
    "            dropout=params['dropout_value'],\n",
    "            )\n",
    "            \n",
    "        model.model.to(device)\n",
    "        \n",
    "        try:\n",
    "            rocauc_score= run_ext(dataset_X, dataset_y, model, epoch, test_X, test_y,traindataset,tar_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            rocauc_score = e\n",
    "            print(e)\n",
    "\n",
    "        params_data.loc[params_data['targets'] == (tar_id+'.csv'), 'external_rocauc'] = rocauc_score\n",
    "\n",
    "    data_all = pd.concat([data_all, params_data], ignore_index=True)\n",
    "    \n",
    "data_all.dropna(axis=0, how='any', inplace=True)\n",
    "data_all.to_excel(external_path+algorithm+'_ex_roc.xlsx',index=False)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
